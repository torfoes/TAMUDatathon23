{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148004, 784) (149736, 784) (137847, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data0 = np.load('quick_draw_data/ambulance.npy')\n",
    "data1 = np.load('quick_draw_data/angel.npy')\n",
    "data2 = np.load('quick_draw_data/animal migration.npy')\n",
    "print(data0.shape, data1.shape, data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148004\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149736\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMlElEQVR4nO3cS4iW9d/H8d/E2F/MI0InqKzIXERRmqUVGIlWFHRQiJDaZIuogaLAWmQKEkUFRiKWhosOlIsgjSAhw1RwY0UHpBSNiCIyycy0jPtZ/T/Lh/lez+M0Tq/X+v5w3Yw6765F375er9drANBaO+Wf/gIADB+iAECIAgAhCgCEKAAQogBAiAIAIQoARP9gP9jX13civwcAJ9hg/l9lbwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMeiDePB/NWXKlE67uXPnljeTJk0qb3bv3l3ebNq0qbwZzFEy+Kd4UwAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/HoZNGiReXNunXrOj3r1FNP7bQbCrt27Spv5s2b1+lZBw4c6LSDCm8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQrqXRyxRVXlDd//vlnp2dNnTq1vPnhhx/Km9tvv728ef3118ubBx98sLxprbVly5Z12kGFNwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcBCPTr777rvyZsyYMZ2eNWrUqPKmy/G9t956q7xZtGhRebNgwYLypjUH8Rga3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAoq/X6/UG9cG+vhP9XTiJTJ48ubz55ptvOj1rz5495c3AwMCQPOfZZ58tb6699tryprXWpk6d2mkH/zWYX/feFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCQTyGzLx58zrt3nvvvfKmv7+/07OqDhw4UN7s37+/07NmzJjRaQf/5SAeACWiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMTQXA1jxJk7d255c+edd3Z61tatW8ub6dOnlzcTJkwobyZOnFjerFixoryBoeJNAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwJZVOZsyYUd50uazaWmtjxowpb7pcPP3kk0/Km4ULF5Y3e/fuLW+6mjZtWnnz9NNPlzfXXXddeTNp0qTyprXWTjml/t+yb731Vnlz7733ljfHjh0rb4YbbwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA0dfr9XqD+mBf34n+LkPuP//5T3nz2muvlTc33HBDedPVwYMHy5v77ruvvNmyZUt509X7779f3syaNau82bdvX3lz+eWXlzdd/y09+uij5c3y5cvLm19//bW86XJw7qeffipvWmtt4sSJ5c3DDz9c3rz77rvlzR133FHeDKXB/Lr3pgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQ/f/0F/j/0uXI2IYNG8qbm2++ubxZvXp1efP777+XN621Nn/+/PLmgw8+KG+WLFlS3qxcubK8aa21a665przZvXt3eTNt2rTypoulS5cO2e6NN94obwYGBsqbAwcOlDdD6ZdffilvVqxYUd6cddZZ5U1rrf3www+ddieCNwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAGDEH8e6+++7y5tZbby1v7r///vLmlVdeKW+6WrZsWXmzZs2a8ua5554rb6ZPn17etNbauHHjypudO3eWN1deeWV5c9NNN5U3Tz75ZHnTWmsvvfRSefPQQw91etZI8+WXX5Y3XY5sTp48ubxpzUE8AIYpUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIEXMl9YknnihvduzYUd6sXbu2vBlKf/zxR3lzzz33lDfbtm0rb2688cbyprXW/v777/Lmww8/LG8efPDB8ubo0aPlzeLFi8ub1lpbv359px3d/py6GD169JA850TypgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQw+4gXn9/t6900UUXlTfLly8vb3q9XnkzEr388svlzYIFCzo9a9euXeXN559/3ulZVWeeeWZ5s27duhPwTfjf9PX1Dclzuv7+Gk68KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEsLvedO6553bajRo1qrzZu3dvp2fR7ec9a9asTs9avXp1ebN///7y5vjx4+XNBRdcUN4w9Lr83fvrr7/Kmy+++KK8GW68KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEsDuIN3r06CF71uTJk4fsWSPNzJkzy5uxY8d2etaWLVvKmy7H7b777rvyxkG8odfX11fe3HjjjeXNzp07y5vDhw+XN8ONNwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAGHYH8b766qtOuy5H0x577LHy5tVXXy1vjhw5Ut4Md3PmzClvuhypa6217du3d9pVff311+XNpZdeegK+yb9Dl8N2rbX2/PPPlzdXXXVVebN48eLyZiTwpgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA9PV6vd6gPtjxouFQufrqq8ubrVu3ljfbtm0rb2655ZbyZrhfVt28eXN5M27cuE7P6vJn28XAwEB5s3LlyvLmoosuKm9aa23Pnj2ddkNh9uzZ5c0LL7zQ6VldLp4+88wz5c2SJUvKm+FuML/uvSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxIg5iNfFbbfdVt68/fbb5c23335b3qxdu7a8aa21TZs2lTf79+8vb3788cfyZtWqVeVNa0N3mOz0008vb77//vvy5qmnnipvWmttxYoV5c2UKVPKmy7H4xYuXFje7Nu3r7xprdvfhw0bNnR61kjjIB4AJaIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxL/6IF4Xc+bMKW8ef/zx8mbu3LnlTWutnXJKvfPHjx8vb/r7+8ubjz/+uLxprbWBgYHy5tNPP+30rKodO3aUN9OmTev0rC5HErv87I4ePVredDnW9+KLL5Y3rbV27NixTjscxAOgSBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAqF81+5f76KOPhmRz9tlnlzettTZr1qzy5oEHHihvrr/++vJmwoQJ5U1rrZ1//vnlzXA+iNflz6i11h555JHyZs2aNeXN0qVLy5uff/65vGF48qYAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEH29Xq83qA/29Z3o78I/ZPPmzeXN2LFjy5uuh+CGs/Hjx5c3XY/HrV+/vry5//77Oz2LkWkwv+69KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQ/f/0F+Cfd8kll5Q377zzzgn4JiefQ4cOlTcbN27s9Kz58+eXN12uGw/ycDIjlDcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgHAQb4QZN25ceXPGGWeUNxdffHF5c9lll5U3rbX22WefddoNV2+++Wan3R133FHezJ49u7zZvn17ecPI4U0BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIBzEG2EuvPDC8qavr6+8mTp1anmzefPm8qa11latWlXenHbaaeXNhAkTypvx48cPyXNaa+3IkSPlzV133VXeOIj37+ZNAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACD6er1eb1Af7HA0jaE3ceLE8mb58uXlzZo1a8qbjRs3ljettXbOOeeUN7/99lt5c/DgwfLm8OHD5c2hQ4fKm66mTJlS3nT5eXNyGMyve28KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQrqXCSOO+888qbmTNnljcbNmwobzg5uJIKQIkoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOEgHsC/hIN4AJSIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABD9g/3gIO/mAXAS86YAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA/A/tsgwkXQqRLwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137847\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(len(data0))\n",
    "# Load the first image from the loaded data\n",
    "image = data0[3].reshape(28, 28)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Turn off the axis numbers\n",
    "plt.show()\n",
    "print(len(data1))\n",
    "# Load the first image from the loaded data\n",
    "image = data1[3].reshape(28, 28)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Turn off the axis numbers\n",
    "plt.show()\n",
    "print(len(data2))\n",
    "# Load the first image from the loaded data\n",
    "image = data2[3].reshape(28, 28)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Turn off the axis numbers\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] training loss: 3.954\n",
      "[1, 200] training loss: 3.922\n",
      "[1, 300] training loss: 3.928\n",
      "[1, 400] training loss: 3.924\n",
      "[1, 500] training loss: 3.923\n",
      "[1, 600] training loss: 3.926\n",
      "[1, 700] training loss: 3.925\n",
      "[1, 800] training loss: 3.922\n",
      "[1, 900] training loss: 3.926\n",
      "[1, 1000] training loss: 3.924\n",
      "[1, 1100] training loss: 3.924\n",
      "[1, 1200] training loss: 3.926\n",
      "[1, 1300] training loss: 3.926\n",
      "[1, 1400] training loss: 3.926\n",
      "[1, 1500] training loss: 3.925\n",
      "[1, 1600] training loss: 3.925\n",
      "[1, 1700] training loss: 3.925\n",
      "[1, 1800] training loss: 3.923\n",
      "[1, 1900] training loss: 3.926\n",
      "[1, 2000] training loss: 3.924\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.flat import FlattenedDoodleSet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Custom transform to handle 1D and 2D numpy arrays\n",
    "class AddChannelDim:\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            if pic.ndim == 1:  # If 1D numpy array\n",
    "                side_length = int(np.sqrt(len(pic)))  # Assuming the doodles are square images\n",
    "                pic = pic.reshape(side_length, side_length)\n",
    "            if pic.ndim == 2:  # Now check if the array is 2D\n",
    "                pic = np.expand_dims(pic, axis=2)  # Add a channel dimension\n",
    "        return pic\n",
    "\n",
    "# Rest of the code remains unchanged...\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    AddChannelDim(),          # Add channel dimension if 2D numpy array\n",
    "    transforms.ToPILImage(),  # Convert numpy.ndarray to PIL.Image\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor()  # Convert PIL.Image back to tensor for PyTorch\n",
    "])\n",
    "\n",
    "# Load full_dataset with the transform\n",
    "full_dataset = FlattenedDoodleSet(data_dir='./quick_draw_data', transform=transform)\n",
    "\n",
    "\n",
    "# Split into train, validation, and test datasets\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Define CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(1152, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        x = self.dropout1(self.relu(self.fc1(x)))\n",
    "        x = self.dropout2(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "num_classes = len(full_dataset.class_to_idx)\n",
    "model = CNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "\n",
    "# Train and validate\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "num_epochs = 3\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] training loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"[{epoch + 1}] validation loss: {avg_val_loss:.3f}\")\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "    else:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Test the model\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test dataset: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
